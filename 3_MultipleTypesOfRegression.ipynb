{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>color_G</th>\n",
       "      <th>color_H</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clarity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>755</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.044963</td>\n",
       "      <td>-0.039076</td>\n",
       "      <td>-0.647096</td>\n",
       "      <td>-1.273878</td>\n",
       "      <td>-1.228620</td>\n",
       "      <td>-1.258205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.835861</td>\n",
       "      <td>-0.242558</td>\n",
       "      <td>-0.647096</td>\n",
       "      <td>-0.803053</td>\n",
       "      <td>-0.888263</td>\n",
       "      <td>-0.871936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.961322</td>\n",
       "      <td>-1.734764</td>\n",
       "      <td>0.655005</td>\n",
       "      <td>-1.025140</td>\n",
       "      <td>-1.045351</td>\n",
       "      <td>-1.200980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.044963</td>\n",
       "      <td>-0.174731</td>\n",
       "      <td>-0.647096</td>\n",
       "      <td>-1.238344</td>\n",
       "      <td>-1.246074</td>\n",
       "      <td>-1.258205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9533</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.464255</td>\n",
       "      <td>1.046165</td>\n",
       "      <td>-1.081129</td>\n",
       "      <td>1.391174</td>\n",
       "      <td>1.328423</td>\n",
       "      <td>1.531517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         price  cut_Fair  cut_Good  cut_Ideal  cut_Premium  cut_Very Good  \\\n",
       "clarity                                                                     \n",
       "4          755         0         0          0            0              1   \n",
       "2          990         0         0          0            1              0   \n",
       "1          650         0         0          0            1              0   \n",
       "5          878         0         0          1            0              0   \n",
       "3         9533         0         0          0            0              1   \n",
       "\n",
       "         color_D  color_E  color_F  color_G  color_H  color_I  color_J  \\\n",
       "clarity                                                                  \n",
       "4              0        1        0        0        0        0        0   \n",
       "2              1        0        0        0        0        0        0   \n",
       "1              1        0        0        0        0        0        0   \n",
       "5              0        0        0        1        0        0        0   \n",
       "3              0        0        0        0        0        1        0   \n",
       "\n",
       "            carat     depth     table         x         y         z  \n",
       "clarity                                                              \n",
       "4       -1.044963 -0.039076 -0.647096 -1.273878 -1.228620 -1.258205  \n",
       "2       -0.835861 -0.242558 -0.647096 -0.803053 -0.888263 -0.871936  \n",
       "1       -0.961322 -1.734764  0.655005 -1.025140 -1.045351 -1.200980  \n",
       "5       -1.044963 -0.174731 -0.647096 -1.238344 -1.246074 -1.258205  \n",
       "3        1.464255  1.046165 -1.081129  1.391174  1.328423  1.531517  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('datasets/diamonds_processed.csv', index_col=0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On definit ici une fonction par type d'algorithm afin de pouvoir les appeler rapidement\n",
    "# On commence par la regression lineaire que l'on a vu auparavant\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linear_model(x_train, y_train):\n",
    "    \n",
    "    print (\"Linear Regression\")\n",
    "    linear_regression = LinearRegression()\n",
    "    \n",
    "    linear_regression.fit(x_train, y_train)\n",
    "    \n",
    "    return linear_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on implemente maintenant la méthode permettant de réaliser le lassot\n",
    "# Pour rapplel, grace a son coefficient le lasso va permettre d'éviter que les data soient\n",
    "# sur entrainer avec les données de train (overfit) en pondérant les colonnes\n",
    "# alpha est la force de la regularisation sur les résultats\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def lasso_model(x_train, y_train):\n",
    "    \n",
    "    print(\"Lasso Regression\")\n",
    "    lasso_regression = Lasso(alpha=0.8, max_iter=10000)\n",
    "    \n",
    "    lasso_regression.fit(x_train, y_train)\n",
    "    \n",
    "    return lasso_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On effectue la meme chose avec le ridge regression model qui est assez proche du lasso (cf formule)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def ridge_model(x_train, y_train):\n",
    "    \n",
    "    print(\"Ridge Regression\")\n",
    "    ridge_regression = Ridge(alpha=0.9)\n",
    "    \n",
    "    ridge_regression.fit(x_train, y_train)\n",
    "    \n",
    "    return ridge_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On implemente un dernier type de données qui est le SGD Regressor\n",
    "# Comme nous l'avons vu dans la partie theorique, celui-ci utilise la méthode itérative du gradient\n",
    "# Descendant pour trouver le MSE minimale.\n",
    "# Celui-ci est idéal pour des dataset tres grand (plus de 100 000 lignes)\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "def sgd_model(x_train, y_train):\n",
    "    \n",
    "    print(\"SGD Regression\")\n",
    "    sgd_regression = SGDRegressor(max_iter=2000)\n",
    "    \n",
    "    sgd_regression.fit(x_train, y_train)\n",
    "    \n",
    "    return sgd_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créé ensuite une fonction qui va permettre d'évaluer facilement les fonctions\n",
    "# que l'on vient d'établir sur chacun des modèles\n",
    "\n",
    "def build_and_train_model(data, target_name, reg_fn):\n",
    "    \n",
    "    X = data.drop(target_name, axis=1)\n",
    "    Y = data[target_name]\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "        train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "    model = reg_fn(x_train, y_train)\n",
    "    \n",
    "    score = model.score(x_train, y_train)\n",
    "    print(\"Training Score : \", score)\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    r_score = r2_score(y_test, y_pred)\n",
    "    print(\"Testing Score : \", r_score)\n",
    "    \n",
    "    return {'model' : model,\n",
    "           'x_train' : x_train,\n",
    "           'x_test' : x_test,\n",
    "           'y_train' : y_train,\n",
    "           'y_pred' : y_pred}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "Training Score :  0.8687159077114386\n",
      "Testing Score :  0.8902332254504001\n"
     ]
    }
   ],
   "source": [
    "# On a construit toutes nos fonctions on les appelle puis on compare les performances\n",
    "linear_reg = build_and_train_model(data, \"price\", linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression\n",
      "Training Score :  0.8687077356234202\n",
      "Testing Score :  0.8904033689237156\n"
     ]
    }
   ],
   "source": [
    "lasso_reg = build_and_train_model(data, \"price\", lasso_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression\n",
      "Training Score :  0.8687277142815064\n",
      "Testing Score :  0.8902786982041868\n"
     ]
    }
   ],
   "source": [
    "ridge_reg = build_and_train_model(data, \"price\", ridge_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Regression\n",
      "Training Score :  0.867244050454426\n",
      "Testing Score :  0.8913836069089198\n"
     ]
    }
   ],
   "source": [
    "sgd_reg = build_and_train_model(data, \"price\", sgd_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On constate ici que les résultats sont très proches quelque soit la méthode\n",
    "# Cela est du au fait que la linear regression n'a pas overfit au vu du fait que les données\n",
    "# était assez peu nombreuses et qu'il y avait peu de colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
